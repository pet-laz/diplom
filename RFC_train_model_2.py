from sklearn.model_selection import train_test_split
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
import joblib
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    classification_report,
    confusion_matrix
)
import seaborn as sns
import matplotlib.pyplot as plt

def split_dataset(input_file, test_size=0.2):
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    df = pd.read_csv(input_file, sep=';', encoding='utf-8')
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–∏–º–ø—Ç–æ–º—ã –≤ –±–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    all_symptoms = []
    for _, row in df.iterrows():
        symptoms = [str(s).strip() for s in row[3:] if pd.notna(s) and str(s).strip() != '']
        for s in symptoms:
            if s not in all_symptoms:
                all_symptoms.append(s)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏—è
    all_symptoms = sorted(all_symptoms)
    # –°–æ–∑–¥–∞–µ–º –±–∏–Ω–∞—Ä–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É —Å–∏–º–ø—Ç–æ–º–æ–≤
    X = []
    y = []
    for _, row in df.iterrows():
        symptoms =  [s for s in row.iloc[3:] if pd.notna(s)]
        x_row = [1 if symptom in symptoms else 0 for symptom in all_symptoms]
        X.append(x_row)
        y.append(row['Name'])
    
    # –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, 
        test_size=test_size,
        stratify=y,
        random_state=42
    )
    
    return X_train, X_test, y_train, y_test, all_symptoms

def evaluate_model(model, X_test, y_test):
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
    y_pred = model.predict(X_test)
    
    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    
    print("\nüìä –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
    print(f"Accuracy (—Ç–æ—á–Ω–æ—Å—Ç—å): {accuracy:.4f}")
    print(f"Precision (—Ç–æ—á–Ω–æ—Å—Ç—å): {precision:.4f}")
    print(f"Recall (–ø–æ–ª–Ω–æ—Ç–∞): {recall:.4f}")
    print(f"F1-score: {f1:.4f}")
    
    # –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º
    print("\nüìã –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º:")
    print(classification_report(y_test, y_pred))
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫
    plt.figure(figsize=(10, 8))
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫')
    plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã')
    plt.ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã')
    plt.show()

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
X_train, X_test, y_train, y_test, all_symptoms = split_dataset("expanded_dataset.csv", 0.3)

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
clf = RandomForestClassifier(
    n_estimators=200,
    max_depth=30,
    class_weight='balanced',
    random_state=42
)
clf.fit(X_train, y_train)

# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
evaluate_model(clf, X_test, y_test)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
joblib.dump(clf, 'trained_model.pkl')
joblib.dump(all_symptoms, 'all_symptoms.pkl')

print("\n‚úÖ –ú–æ–¥–µ–ª—å RandomForest —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ 'trained_model.pkl' –∏ 'all_symptoms.pkl'")
